{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-Zt67QDzbcVI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "# install this module for extracting info from fas file instead of doing by hand\n",
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c-mDXXQUnAen"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from Bio import SeqIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry_YA5rKnLU1"
      },
      "source": [
        "Our dataset comprises a folder containing ten FASTA files, each file consisting of numerous sequence names referred to as \"sequences.\" In addition to the existing data, we are introducing an additional class as a label. This label will be represented by the file names, indicating the family to which the various sequences belong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JB7hEW9inDOU"
      },
      "outputs": [],
      "source": [
        "class SequenceBuilder:\n",
        "    def __init__(self, folder_path):\n",
        "        self.folder_path = folder_path\n",
        "\n",
        "    def sequence_builder(self):\n",
        "        sequences = {}\n",
        "        data = []\n",
        "\n",
        "        for filename in os.listdir(self.folder_path):\n",
        "            file_path = os.path.join(self.folder_path, filename)\n",
        "            if os.path.isfile(file_path):  # Exclude directories\n",
        "                for record in SeqIO.parse(file_path, \"fasta\"):\n",
        "                    sequence_name = record.id\n",
        "                    sequence = str(record.seq)\n",
        "                    sequences[sequence_name] = [sequence, filename]\n",
        "\n",
        "        # Build a dataframe\n",
        "        for key, value in sequences.items():\n",
        "            data.append([key, value[0], value[1]])\n",
        "        df = pd.DataFrame(data, columns=['seq name', 'seq', 'class or file name'])\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YVQWSfhqnQgJ"
      },
      "outputs": [],
      "source": [
        "#build a dataframe# Example usage\n",
        "folder_path =  \"/content/drive/MyDrive/cs612_sequences\"\n",
        "builder = SequenceBuilder(folder_path)\n",
        "df = builder.sequence_builder()\n",
        "#make sure to change the directory before saving or it will go exacly to the fas file location\n",
        "#df.to_csv('Sequence DataFrame.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reads the file as a csv. if we ever wanted to change anything about the csv, we have to add it here\n",
        "class CSVHandler():\n",
        "  def __init__(self,file_path):\n",
        "    self.file_path = file_path\n",
        "\n",
        "  def read_csv(self, file_path):\n",
        "     df = pd.read_csv(self.file_path)\n",
        "     return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aZwiBvV8n3t9"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/new_dataset.csv'\n",
        "csvhandler = CSVHandler(file_path)\n",
        "\n",
        "#the dataframe that will be used:\n",
        "df = csvhandler.read_csv(file_path)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize and encode the sequences\n",
        "train_encodings = tokenizer(train_df['seq'].tolist(), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_df['seq'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Prepare the labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_df['class or file name'].tolist())\n",
        "val_labels = label_encoder.transform(val_df['class or file name'].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map encoded labels back to original classes\n",
        "train_class_names = label_encoder.inverse_transform(train_labels)\n",
        "val_class_names = label_encoder.inverse_transform(val_labels)\n",
        "\"\"\"\n",
        "# Print the mapping\n",
        "for label, class_name in zip(train_labels, train_class_names):\n",
        "    print(f\"Encoded label: {label}, Class name: {class_name}\")\n",
        "\"\"\"# Create a set to store unique labels and class names\n",
        "unique_labels = set()\n",
        "for label, class_name in zip(train_labels, train_class_names):\n",
        "    unique_labels.add((label, class_name))\n",
        "\n",
        "# Print the unique labels and class names\n",
        "for label, class_name in unique_labels:\n",
        "    print(f\"Encoded label: {label}, Class name: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "skJwf5q9t4U_"
      },
      "outputs": [],
      "source": [
        "# Define the dataset\n",
        "class SequenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pu5bwmMft54i"
      },
      "outputs": [],
      "source": [
        "# Create instances of the dataset\n",
        "train_dataset = SequenceDataset(train_encodings, train_labels)\n",
        "val_dataset = SequenceDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iQTNViC2uAQA"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.linear(pooled_output)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLxiwk9VuE93",
        "outputId": "a16785bc-a9d9-48bf-b469-4cbd5f0f5d5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Set the device to use\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create an instance of the model and move it to the device\n",
        "model = MyModel(num_classes=len(label_encoder.classes_)).to(device)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)  # Adjust learning rate if needed\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "best_val_accuracy = 0.0  # Track the best validation accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7swO7d7NbKFI",
        "outputId": "bcde9841-e79d-49f0-e8f1-a598ac74a5d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10:\n",
            "Train Loss: 2.3023 | Train Acc: 15.49%\n",
            "Validation Loss: 2.2829 | Validation Acc: 13.24%\n",
            "Epoch 2/10:\n",
            "Train Loss: 2.2923 | Train Acc: 16.30%\n",
            "Validation Loss: 2.3052 | Validation Acc: 13.24%\n",
            "Epoch 3/10:\n",
            "Train Loss: 2.2575 | Train Acc: 15.71%\n",
            "Validation Loss: 2.2865 | Validation Acc: 13.24%\n",
            "Epoch 4/10:\n",
            "Train Loss: 2.2622 | Train Acc: 16.96%\n",
            "Validation Loss: 2.2609 | Validation Acc: 18.82%\n",
            "Epoch 5/10:\n",
            "Train Loss: 2.2517 | Train Acc: 17.48%\n",
            "Validation Loss: 2.2906 | Validation Acc: 11.76%\n",
            "Epoch 6/10:\n",
            "Train Loss: 2.2640 | Train Acc: 16.22%\n",
            "Validation Loss: 2.3038 | Validation Acc: 13.24%\n",
            "Epoch 7/10:\n",
            "Train Loss: 2.2552 | Train Acc: 15.93%\n",
            "Validation Loss: 2.2553 | Validation Acc: 18.82%\n",
            "Epoch 8/10:\n",
            "Train Loss: 2.2525 | Train Acc: 17.40%\n",
            "Validation Loss: 2.2665 | Validation Acc: 13.24%\n",
            "Epoch 9/10:\n",
            "Train Loss: 2.2507 | Train Acc: 16.37%\n",
            "Validation Loss: 2.3115 | Validation Acc: 13.24%\n",
            "Epoch 10/10:\n",
            "Train Loss: 2.2695 | Train Acc: 16.45%\n",
            "Validation Loss: 2.2655 | Validation Acc: 13.24%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, val_loader, criterion, optimizer, device):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.best_val_accuracy = 0.0\n",
        "\n",
        "    def train(self, num_epochs):\n",
        "        for epoch in range(num_epochs):\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            for batch in self.train_loader:\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['labels'].to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                outputs = self.model(input_ids, attention_mask)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "                train_total += labels.size(0)\n",
        "\n",
        "            train_loss /= len(self.train_loader)\n",
        "            train_accuracy = train_correct / train_total\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.val_loader:\n",
        "                    input_ids = batch['input_ids'].to(self.device)\n",
        "                    attention_mask = batch['attention_mask'].to(self.device)\n",
        "                    labels = batch['labels'].to(self.device)\n",
        "\n",
        "                    outputs = self.model(input_ids, attention_mask)\n",
        "                    loss = self.criterion(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = torch.max(outputs, dim=1)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "            val_loss /= len(self.val_loader)\n",
        "            val_accuracy = val_correct / val_total\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.2%}\")\n",
        "            print(f\"Validation Loss: {val_loss:.4f} | Validation Acc: {val_accuracy:.2%}\")\n",
        "\n",
        "            # Save the model if it has the best validation accuracy so far\n",
        "            if val_accuracy > self.best_val_accuracy:\n",
        "                torch.save(self.model.state_dict(), 'best_model.pt')\n",
        "                self.best_val_accuracy = val_accuracy\n",
        "\n",
        "            # Debugging: Print some predictions and targets\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                sample_inputs = next(iter(self.val_loader))\n",
        "                input_ids = sample_inputs['input_ids'].to(self.device)\n",
        "                attention_mask = sample_inputs['attention_mask'].to(self.device)\n",
        "                labels = sample_inputs['labels'].to(self.device)\n",
        "\n",
        "                outputs = self.model(input_ids, attention_mask)\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "                # Convert label indices to class labels\n",
        "                predicted_classes = label_encoder.inverse_transform(predicted.cpu().numpy())\n",
        "                target_classes = label_encoder.inverse_transform(labels.cpu().numpy())\n",
        "\n",
        "                print(\"Sample Predictions:\")\n",
        "                print(\"Predicted:\", predicted_classes[:5])\n",
        "                print(\"Target:\", target_classes[:5])\n",
        "\n",
        "trainer = Trainer(model, train_loader, val_loader, criterion, optimizer, device)\n",
        "trainer.train(num_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = '/content/drive/MyDrive/NEW_model_with_dash.pt'\n",
        "torch.save(model.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can run the code below separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model, label_encoder):\n",
        "        self.model = model\n",
        "        self.label_encoder = label_encoder\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def predict(self, sequence):\n",
        "        # Tokenize and encode the input sequence\n",
        "        tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "        inputs = tokenizer(sequence, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "        # Move the input tensors to the appropriate device\n",
        "        inputs = {key: val.to(self.device) for key, val in inputs.items()}\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        self.model.eval()\n",
        "\n",
        "        # Perform the prediction\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(inputs['input_ids'], inputs['attention_mask'])\n",
        "            probabilities = torch.softmax(logits, dim=1)\n",
        "            predicted_label = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "        # Convert the predicted label index to the original class name\n",
        "        predicted_class = self.label_encoder.inverse_transform([predicted_label])[0]\n",
        "\n",
        "        return predicted_class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#EXAMPLE:\n",
        "# Instantiate the predictor class\n",
        "predictor = Predictor(model, label_encoder)\n",
        "\n",
        "# Perform the prediction\n",
        "random_sequence = 'MAEELSWKQDGATLHFFGELDGVTVNSLWQQREKMVTGINLFELSGLTRVDTAGLALLIHLTAIVARQGNKIELAAATDNLRTLAQLYNLPEALLPH----KTVEITNKLGMHARPAMKLFELVQSFDAEVMLRNEAGTEAEASSVIALLMLDSAKGGHIEIEVTGPEEEQALAAVIALFNAGFDED'\n",
        "predicted_class = predictor.predict(random_sequence)\n",
        "\n",
        "print(\"Predicted class:\", predicted_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Encoded label: 1, Class name: ISCA_ISCR_20_id90.fas\n",
        "\n",
        "Encoded label: 7, Class name: YDBL_YNBE_20_id90.fas\n",
        "\n",
        "Encoded label: 8, Class name: YEFM_YOEB_20_id90.fas\n",
        "\n",
        "Encoded label: 6, Class name: YAGP_YAHO_20_id90.fas\n",
        "\n",
        "Encoded label: 9, Class name: YFIB_YJAB_20_id90.fas\n",
        "\n",
        "Encoded label: 2, Class name: MLAB_PTSO_20_id90.fas\n",
        "\n",
        "Encoded label: 3, Class name: RNPA_YBCJ_20_id90.fas\n",
        "\n",
        "Encoded label: 0, Class name: CSPD_IF1_20_id90.fas\n",
        "\n",
        "Encoded label: 5, Class name: TESA_THIO_20_id90.fas\n",
        "\n",
        "Encoded label: 4, Class name: SLYX_TUSB_20_id90.fas\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
